{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waghmareps12/PYTHON_DSA/blob/main/PROMPT_ENGINEERING.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "special-sleeve",
      "metadata": {
        "id": "special-sleeve"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=<>)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-QWBCCEtNCCC",
      "metadata": {
        "id": "-QWBCCEtNCCC"
      },
      "outputs": [],
      "source": [
        "def get_response(prompt):\n",
        "  # Create a request to the chat completions endpoint\n",
        "  response = client.chat.completions.create(model = \"gpt-3.5-turbo\",\n",
        "                                            messages = [{\"role\": \"user\",\"content\": prompt}],temperature = 0)\n",
        "  return response.choices[0].message.content\n",
        "\n",
        "# Test the function with your prompt\n",
        "response = get_response(\"write a poem about ChatGPT.\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BA3VB2yrNB95",
      "metadata": {
        "id": "BA3VB2yrNB95"
      },
      "outputs": [],
      "source": [
        "####"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XxV0iCAZOHf9",
      "metadata": {
        "id": "XxV0iCAZOHf9"
      },
      "source": [
        "### Priciple to use while writing Prompts\n",
        "\n",
        "1.   AVoid ambiguous word:\n",
        "\n",
        "    (like : understad, think, try, feel, know)\n",
        "      \n",
        "      instead use (Write, explain , complete, Describe, Evaluate )\n",
        "\n",
        "2.  Provide specific and detailed instructions regarding:\n",
        "    *   context\n",
        "    *   output length\n",
        "    *   Format\n",
        "    *   Style\n",
        "    *   Audience\n",
        "\n",
        "\n",
        "3.  Crafting a Well structured prompt with delimiters:\n",
        "\n",
        "\n",
        "    Start the prompt with instructions\n",
        "    Use Delimiters (parenthesis, brackets, backticks, etc.) to specify the input parts\n",
        "    mention with delimeters are used\n",
        "    Example: prompt = \"\"\"Summarize the text delimited by triple backticks into bullet points.   ```TEXT GOES HERE```\"\"\"\n",
        "\n",
        "    use formated strings\n",
        "    text = \"This is a sample text to summarize\"\n",
        "    prompt = f\"\"\"Summarize the text delimited by triple backticks into bullet points.```{text}```\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fMIwIUkBNB6L",
      "metadata": {
        "id": "fMIwIUkBNB6L"
      },
      "outputs": [],
      "source": [
        "# Create a prompt that completes the story\n",
        "\n",
        "prompt = f\"\"\"completes the given story delimited by triple backticks.\n",
        "```{story}```\"\"\"\n",
        "\n",
        "# Get the generated response\n",
        "response = get_response(prompt)\n",
        "\n",
        "print(\"\\n Original story: \\n\", story)\n",
        "print(\"\\n Generated story: \\n\", response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0IsyMDB-NB1X",
      "metadata": {
        "id": "0IsyMDB-NB1X"
      },
      "outputs": [],
      "source": [
        "# Create a request to complete the story\n",
        "# Create a request to complete the story\n",
        "prompt = f\"\"\"Complete the story delimited by triple backticks with only two paragraphs using the style of William Shakespeare.\n",
        " ```{story}```\"\"\"\n",
        "\n",
        "# Get the generated response\n",
        "response = get_response(prompt)\n",
        "\n",
        "print(\"\\n Original story: \\n\", story)\n",
        "print(\"\\n Generated story: \\n\", response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2hDRFIZ7VDhO",
      "metadata": {
        "id": "2hDRFIZ7VDhO"
      },
      "source": [
        "### Structured Output\n",
        "clearly mention the expected co;umns\n",
        "\n",
        "\n",
        "list : requorement for numbering should be mentioned in the prompt\n",
        "\n",
        "\n",
        "Structured Paragraphs: Mention structure requirements in prompt\n",
        "\n",
        "\n",
        "> prompt = \"Provide a structured paragraph with clear headings and subheadings about the benefits of regular exercise on overall health and well-being.\"\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0_L33R7NBwX",
      "metadata": {
        "id": "b0_L33R7NBwX"
      },
      "outputs": [],
      "source": [
        "text = '''\"Once upon a time in a quaint little village, there lived a curious young boy named\n",
        "David. David was [...]\"'''\n",
        "instructions = \"You will be provided with a text delimited by triple backticks. Generate a suitable title for it.\"\n",
        "output_format = \"\"\"Use the following format for the output:\n",
        "- Text: <text we want to title>\n",
        "- Title: <the generated title>\"\"\"\n",
        "prompt = instructions + output_format + f\"```{text}```\"\n",
        "print(get_response(prompt))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OqWTC3-lWt8g",
      "metadata": {
        "id": "OqWTC3-lWt8g"
      },
      "source": [
        "##### Conditional prompts ðŸ‡°\n",
        "Incorporate logic or conditions\n",
        "Conditional prompts follow an if-else style\n",
        "\n",
        "\n",
        "prompt = f\"\"\"You will be provided with a text delimited by triple backticks.\n",
        "If the text is written in English, suggest a suitable title for it.\n",
        "Otherwise, write 'I only understand English' .\n",
        "```{text}```\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "Can incorporate multiple conditions\n",
        "\n",
        "\n",
        "\n",
        "prompt = f\"\"\"You will be provided with a text delimited by triple backticks.\n",
        "If the text is written in English, check if it contains the keyword 'technology'\n",
        ".\n",
        "```{text}```\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uWUYyvUoYnFg",
      "metadata": {
        "id": "uWUYyvUoYnFg"
      },
      "outputs": [],
      "source": [
        "# Create a prompt that generates the table\n",
        "prompt = '''Generate a table containing 10 books with columns for Title, Author, and Year, that you should read given that you are a sci-fi lover.'''\n",
        "\n",
        "\n",
        "# Get the response\n",
        "response = get_response(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6KRpHRhcNBp3",
      "metadata": {
        "id": "6KRpHRhcNBp3"
      },
      "outputs": [],
      "source": [
        "# Create the instructions\n",
        "instructions = \"You will be provided with a text delimited by triple backticks. Infer its language, then generate a suitable title for it. \"\n",
        "\n",
        "# Create the output format\n",
        "output_format = \"\"\"Use the following format for the output:\n",
        "         - Text: <the text>\n",
        "         - Language: <the text language>\n",
        "         - Title: <the generated title>\"\"\"\n",
        "\n",
        "# Create the final prompt\n",
        "prompt = instructions + output_format + f\"```{text}```\"\n",
        "response = get_response(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Smp1tOCleWrN",
      "metadata": {
        "id": "Smp1tOCleWrN"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "G_I8-a9ENBh6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "G_I8-a9ENBh6",
        "outputId": "67e72cdc-e28b-4bf9-ddc9-3b2e8d141a9a"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-3-213c2e3be564>, line 2)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-213c2e3be564>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    instructions =\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Create the instructions\n",
        "instructions =\n",
        "'''You will be provided with a text delimited by triple backticks.\n",
        " Infer its language, and the number of sentences then\n",
        " if the text contains more than one sentence\n",
        " generate a suitable title for it otherwise, write 'N/A' for the title.. '''\n",
        "\n",
        "# Create the output format\n",
        "output_format =\n",
        "\"\"\"Use the following format for the output:\n",
        "         - Text: <the text>\n",
        "         - Language: <the text language>\n",
        "         - N_sentences: <number of sentences>\n",
        "         - Title: <the generated title>\"\"\"\n",
        "\n",
        "prompt = instructions + output_format + f\"```{text}```\"\n",
        "response = get_response(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2MBeINfZeXdU",
      "metadata": {
        "id": "2MBeINfZeXdU"
      },
      "source": [
        "### Few Shot Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dqLe6iGzeXjW",
      "metadata": {
        "id": "dqLe6iGzeXjW"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MnED3wwXNBXa",
      "metadata": {
        "id": "MnED3wwXNBXa"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "  model = \"gpt-3.5-turbo\",\n",
        "  # Provide the examples as previous conversations\n",
        "  messages = [{\"role\": \"user\", \"content\": \"The product quality exceeded my expectations\"},\n",
        "              {\"role\": \"assistant\", \"content\": \"1\"},\n",
        "              {\"role\": \"user\", \"content\": \"I had a terrible experience with this product's customer service\"},\n",
        "              {\"role\": \"assistant\", \"content\": \"-1\"},\n",
        "              # Provide the text for the model to classify\n",
        "              {\"role\": \"user\", \"content\": \"The price of the product is really fair given its features\"}\n",
        "             ],\n",
        "  temperature = 0\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iZcq2EB0kra4",
      "metadata": {
        "id": "iZcq2EB0kra4"
      },
      "source": [
        "### MultiStep Prompting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IF_NzBKunXum",
      "metadata": {
        "id": "IF_NzBKunXum"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"Compose a travel blog as follows:\n",
        "Step 1: Introduce the destination.\n",
        "Step 2: Share personal adventures during the trip.\n",
        "Step 3: Summarize the journey.\n",
        "\"\"\"\n",
        "print(get\n",
        "_\n",
        "response(prompt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gT7nr6irkuN9",
      "metadata": {
        "id": "gT7nr6irkuN9"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create a prompt detailing steps to plan the trip\n",
        "prompt = \"\"\"The plan should have four potential locations for your beach vacation,\n",
        "and each location should have some accommodation options, some activities, and an evaluation of the pros and cons. answer as follows:\n",
        "\n",
        "step 1 :  Mention the location ,\n",
        "step 2 :  share some accomodations options ,\n",
        "step 3 :  share some activities to do  ,\n",
        "step 4 :  evaluate the pros and cons of the location ,\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "response = get_response(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oxTUjCSxoziT",
      "metadata": {
        "id": "oxTUjCSxoziT"
      },
      "outputs": [],
      "source": [
        "\n",
        "code = '''\n",
        "def calculate_rectangle_area(length, width):\n",
        "    area = length * width\n",
        "    return area\n",
        "'''\n",
        "\n",
        "# Create a prompt that analyzes correctness of the code\n",
        "prompt = f\"\"\"Determine the correctness of the code delimited by triple backticks as follows:\n",
        "step 1 : check if the function has correct syntax\n",
        "step 2 : the fucntion takes two inputs,\n",
        "step 3 : the fucntion returns one output.\n",
        "  ```{code}```\"\"\"\n",
        "\n",
        "response = get_response(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AZUG9-zisbZ3",
      "metadata": {
        "id": "AZUG9-zisbZ3"
      },
      "source": [
        "### self_consistency instruction Prompting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iyjdk36csYBh",
      "metadata": {
        "id": "iyjdk36csYBh"
      },
      "outputs": [],
      "source": [
        "# Create the self_consistency instruction\n",
        "self_consistency_instruction = \"\"\"Imagine three completely independent experts who\n",
        "reason differently are answering this question. The final answer is obtained by\n",
        "majority vote. The question is: \"\"\"\n",
        "\n",
        "# Create the problem to solve\n",
        "problem_to_solve = \"\"\"If you own a store that sells laptops and mobile phones. \n",
        "You start your day with 50 devices in the store, out of which 60% are mobile phones.\n",
        " Throughout the day, three clients visited the store, each of them bought one mobile phone,\n",
        " and one of them bought additionally a laptop. Also, you added to your collection 10 laptops\n",
        " and 5 mobile phones. How many laptops and mobile phones do you have by the end of the day?\"\"\"\n",
        "\n",
        "# Create the final prompt\n",
        "prompt = self_consistency_instruction + problem_to_solve\n",
        "\n",
        "response = get_response(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4cc8028",
      "metadata": {},
      "source": [
        "#### Text summarization and expansion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d17c10f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Craft a prompt to summarize the report\n",
        "prompt = f\"\"\"Summarize the review delimited by triple backticks, in maximum five sentences,  \n",
        "focusing on the key features and user experience:  \n",
        "          ```{report}```\"\"\"\n",
        "\n",
        "\n",
        "response = get_response(prompt)\n",
        "\n",
        "print(\"Summarized report: \\n\", response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b53d6217",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Craft a prompt to summarize the product description\n",
        "prompt = f\"\"\"Summarize the text delimited by triple backticks,\n",
        "in no more than five bullet points.    \n",
        " focusing on the product features and specifications.:\n",
        "         ```{product_description}```\"\"\"\n",
        "\n",
        "response = get_response(prompt)\n",
        "\n",
        "print(\"Original description: \\n\", product_description)\n",
        "print(\"Summarized description: \\n\", response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "328bd32d",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Craft a prompt to expand the product's description\n",
        "prompt = f\"\"\"\n",
        "Expand the product description for the Smart Home Security Camera \n",
        "delimited by triple backticks to provide a comprehensive overview of its features,\n",
        " benefits, potential applications, without bypassing the limit of one paragraph. \n",
        " ```{product_description}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_response(prompt)\n",
        "\n",
        "print(\"Original description: \\n\", product_description)\n",
        "print(\"Expanded description: \\n\", response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ec35703",
      "metadata": {},
      "source": [
        "### Text transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5e1a529",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Craft a prompt that translates\n",
        "prompt =  f\"\"\"Translate the English text delimited by triple backticks to French, \n",
        " Spanish, and Japanese: ```{marketing_message}```\"\"\"\n",
        " \n",
        "response = get_response(prompt)\n",
        "\n",
        "print(\"English:\", marketing_message)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fd52fc6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Craft a prompt to transform the text\n",
        "\n",
        "# Craft a prompt to transform the text\n",
        "prompt = f\"\"\"Transform the text delimited by triple backticks with the following two steps:\n",
        "Step 1 - Proofread it without changing its structure\n",
        "Step 2 - Change the tone to be formal and friendly\n",
        " ```{text}```\"\"\"\n",
        "\n",
        "response = get_response(prompt)\n",
        "\n",
        "print(\"Before transformation:\\n\", text)\n",
        "print(\"After transformation:\\n\", response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4098017",
      "metadata": {},
      "source": [
        "### Text analysis\n",
        "\n",
        "\n",
        "Examining text to extract informationText classificationEntity extractionCompanies should seek legal advice when using customer data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63b412b5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Craft a prompt to classify the ticket\n",
        "prompt = f\"\"\"Classify the sentiment of the text delimited by triple backticks as \n",
        " as technical issue, billing inquiry, or product feedback.\n",
        " Give your answer as a single word:            ```{ticket}```\"\"\"\n",
        "\n",
        "response = get_response(prompt)\n",
        "\n",
        "print(\"Ticket: \", ticket)\n",
        "print(\"Class: \", response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "217298d2",
      "metadata": {},
      "outputs": [],
      "source": [
        "Class:  technical issue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25c19880",
      "metadata": {},
      "outputs": [],
      "source": [
        "def break_up_file(tokens, chunk_size, overlap_size):\n",
        "    if len(tokens) <= chunk_size:\n",
        "        yield tokens\n",
        "    chunk = tokens[:chunk_size]\n",
        "    yield chunk\n",
        "    yield from break_up_file(tokens[chunk_size - overlap_size:], chunk_size, overlap_size)\n",
        "\n",
        "def break_up_file_to_chunks(filename, chunk_size=2000, overlap_size=100):\n",
        "    with open(filename, 'r') as f:\n",
        "        text = f.read()\n",
        "    tokens = word_tokenize(text)\n",
        "    return list(break_up_file(tokens, chunk_size, overlap_size))\n",
        "\n",
        "def convert_to_prompt_text(tokenized_text):\n",
        "    prompt_text = \" \".join(tokenized_text)\n",
        "    prompt_text = prompt_text.replace(\" 's\", \"'s\")\n",
        "    return prompt_text\n",
        "\n",
        "filename = \"/content/drive/MyDrive/Colab Notebooks/minutes/data/Round_22_Online_Kickoff_Meeting.txt\"\n",
        "# response = []\n",
        "prompt_response = []\n",
        "chunks = break_up_file_to_chunks(filename)\n",
        "for i, chunk in enumerate(chunks):\n",
        "    prompt_request = \"Summarize this meeting transcript: \" + convert_to_prompt_text(chunks[i])\n",
        "\n",
        "    response = openai.Completion.create(\n",
        "        model=\"text-davinci-003\",\n",
        "        prompt=prompt_request,\n",
        "        temperature=0.5,\n",
        "        max_tokens=500,\n",
        "        top_p=1,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0\n",
        "    )\n",
        "\n",
        "    prompt_response.append(response[\"choices\"][0][\"text\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d6c617c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Craft a few-shot prompt to get the ticket's entities\n",
        "prompt = f\"\"\"Ticket: {ticket_1} -> Entities: {entities_1}\n",
        "            Ticket: {ticket_2} -> Entities: {entities_2}\n",
        "            Ticket: {ticket_3} -> Entities: {entities_3}\n",
        "            Ticket: {ticket_4} -> Entities: \"\"\"\n",
        "\n",
        "response = get_response(prompt)\n",
        "\n",
        "print(\"Ticket: \", ticket_4)\n",
        "print(\"Entities: \", response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be4c15cd",
      "metadata": {},
      "source": [
        "### Code Genration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7feef15b",
      "metadata": {},
      "outputs": [],
      "source": [
        "examples=\"\"\"input = [10, 5, 8] -> output = 24\n",
        "input = [5, 2, 4] -> output = 12\n",
        "input = [2, 1, 3] -> output = 7\n",
        "input = [8, 4, 6] -> output = 19\n",
        "\"\"\"\n",
        "\n",
        "# Craft a prompt that asks the model for the function\n",
        "prompt = f\"\"\"You are provided with input-output examples delimited by tri\n",
        "ple backticks for a Python function where different factors are associated with project completion time.\n",
        " Each example includes numerical values for the factors and the corresponding estimated completion time.\n",
        "   Write a code for this function.\n",
        " ```{examples}```\"\"\"\n",
        "\n",
        "response = get_response(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b144a5b8",
      "metadata": {},
      "outputs": [],
      "source": [
        "function = \"\"\"def calculate_area_rectangular_floor(width, length):\n",
        "\t\t\t\t\treturn width*length\"\"\"\n",
        "\n",
        "# Craft a multi-step prompt that asks the model to adjust the function\n",
        "prompt = f\"\"\"Modify the function delimited by triple backticks to return the perimeter of the rectangle as well, and to test if the inputs (floor dimensions) are positive, and if not, display appropriate error messages.```{function}```\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77ce243a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Craft a chain-of-thought prompt that asks the model to explain what the function does\n",
        "prompt = f\"\"\"Explain what the function delimited by triple backticks does.  \n",
        "Let's think step by step. ```{function}```\"\"\" \n",
        " \n",
        "response = get_response(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ab13478",
      "metadata": {},
      "source": [
        "##### Building A ChatBOT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd4c454a",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_response(system_prompt, user_prompt):  \n",
        "    messages = [       {\"role\": \"system\", \"content\": system_prompt},  \n",
        "                     {\"role\": \"user\", \"content\": user_prompt}]   \n",
        "    response = client.chat.completions.create( model=\"gpt-3.5-turbo\",       \n",
        "                                                messages=messages, \n",
        "                                                                temperature=0,)    \n",
        "    return response.choices[0].message.content \n",
        "system_prompt = \"<SYSTEM_PROMPT>\" \n",
        "user_prompt = \"<USER_PROMPT>\" \n",
        "print(get_response(system_prompt, user_prompt)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "614c5f56",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the purpose of the chatbot\n",
        "chatbot_purpose = \"\"\"You are the customer support chatbot for an\n",
        "e-commerce platform specializing in electronics. \n",
        "Your role is to assist customers with inquiries, order tracking, \n",
        "and troubleshooting common issues related to their purchases.\"\"\"\n",
        "\n",
        "# Define audience guidelines\n",
        "audience_guidelines = \"\"\"Your primary audience consists of tech-savvy individuals\n",
        "who are interested in purchasing electronic gadgets. \"\"\"\n",
        "\n",
        "# Define tone guidelines\n",
        "tone_guidelines = \"Maintain a professional and user-friendly tone in your responses.\"\n",
        "\n",
        "base_system_prompt = chatbot_purpose + audience_guidelines + tone_guidelines\n",
        "response = get_response(base_system_prompt, \"My new headphones aren't connecting to my device\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0b4945c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the order number condition\n",
        "order_number_condition = \"If the user is asking about an order, and did not specify the order number, reply by asking for this number. \"\n",
        "\n",
        "# Define the technical issue condition\n",
        "technical_issue_condition = \"If the user is talking about a technical issue, start your response with `I'm sorry to hear about your issue with ...` \"\n",
        "\n",
        "# Create the refined system prompt\n",
        "refined_system_prompt = base_system_prompt + order_number_condition + technical_issue_condition\n",
        "\n",
        "response_1 = get_response(refined_system_prompt, \"My laptop screen is flickering. What should I do?\")\n",
        "response_2 = get_response(refined_system_prompt, \"Can you help me track my recent order?\")\n",
        "\n",
        "print(\"Response 1: \", response_1)\n",
        "print(\"Response 2: \", response_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad940745",
      "metadata": {},
      "source": [
        "### Role-playing prompts forchatbots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da8c9c3d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Craft the system_prompt using the role-playing approach\n",
        "system_prompt = \"act as a learning advisor who can interpret learner queries as described and provide the relevant textbook recommendations.\"\n",
        "\n",
        "user_prompt = \"Hello there! I'm a beginner with a marketing background, and I'm really interested in learning about Python, data analytics, and machine learning. Can you recommend some books?\"\n",
        "\n",
        "response = get_response(system_prompt, user_prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e41f266",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "base_system_prompt = \"Act as a learning advisor who receives queries from users mentioning their background, experience, and goals, and accordingly provides a response that recommends a tailored learning path of textbooks, including both beginner-level and more advanced options.\"\n",
        "\n",
        "# Define behavior guidelines\n",
        "behavior_guidelines = \"If the user's query does not include details about their background, experience, or goals, kindly ask them to provide the missing information.\"\n",
        "\n",
        "# Define response guidelines\n",
        "response_guidelines = \"Don't recommend more than three textbooks in the learning path\"\n",
        "\n",
        "system_prompt = base_system_prompt + behavior_guidelines + response_guidelines\n",
        "user_prompt = \"Hey, I'm looking for courses on Python and data visualization. What do you recommend?\"\n",
        "response = get_response(system_prompt, user_prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adfa6c72",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the system prompt\n",
        "system_prompt = \"You are a customer service chatbot for MyPersonalDelivery, a delivery service that offers a wide range of delivery options for various items. You should respond to user queries in a gentle way.\"\n",
        "\n",
        "context_question = \"What types of items can be delivered using MyPersonalDelivery?\"\n",
        "context_answer = \"We deliver everything from everyday essentials such as groceries, medications, and documents to larger items like electronics, clothing, and furniture. However, please note that we currently do not offer delivery for hazardous materials or extremely fragile items requiring special handling.\"\n",
        "\n",
        "# Add the context to the model\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": context_question},\n",
        "            {\"role\": \"assistant\", \"content\": context_answer},\n",
        "            {\"role\": \"user\", \"content\": \"Do you deliver furniture?\"}])\n",
        "response = response.choices[0].message.content\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc7b79ff",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the system prompt\n",
        "system_prompt = f\"\"\"You are a customer service chatbot for MyPersonalDelivery whose service description is delimited by triple backticks. You should respond to user queries in a gentle way.\n",
        " ```{service_description}```\n",
        "\"\"\"\n",
        "\n",
        "user_prompt = \"What benefits does MyPersonalDelivery offer?\"\n",
        "\n",
        "# Get the response to the user prompt\n",
        "response = get_response(system_prompt, user_prompt)\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1cad185",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
